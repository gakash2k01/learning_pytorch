{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset_class_for_simple_NLP_problems.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "58MAA8vFMwal"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NNQCrz1NFZj"
      },
      "source": [
        "# classification/regression problem\n",
        "class CustomDataset:\n",
        "  def __init__(self,data, targets,tokenizer):\n",
        "    self.data = data\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    text = self.data[idx]\n",
        "    target = self.targets[idx]\n",
        "    # if self.target.shape[1] > 1:\n",
        "    #   targets = self.targets[idx,:]\n",
        "    # else:\n",
        "    #   target = self.targets[idx]\n",
        "    input_ids = tokenizer(text)\n",
        "    # padding\n",
        "\n",
        "    return {\n",
        "        \"text\": torch.tensor(input_ids, dtype = torch.long),\n",
        "        \"target\": torch.tensor(target, dtype = torch.long)\n",
        "    }"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGZ9eQ4vOBSV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}